{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608034f5-31f7-4910-9144-5d153934c310",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import statistics as sts\n",
    "from sliceline.slicefinder import Slicefinder\n",
    "import optbinning\n",
    "from dt import *"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d8d7d7d4-de60-4493-8b01-fbb9a98ca8a1",
   "metadata": {},
   "source": [
    "**Reproducibility Notes**\n",
    "\n",
    "The PyPi `sliceline` package requires Python 3.7~3.10.0, which is not the most up-to-date python version. Creating a virtual environment with python 3.9 should work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcd032-9b0c-4bad-9588-3ce4f2883e98",
   "metadata": {},
   "source": [
    "## Defining Reusable Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb3e8d-90b7-4a52-8904-71431ceaec38",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29af4dce-2955-41ae-90fe-9d6a6987cea8",
   "metadata": {},
   "source": [
    "def parse_file(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    train_x, train_y = dt.split_xy(df)\n",
    "    return train_x, train_y, df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "711d8ab3-3642-472c-8eb9-63635045138c",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a61585a-010e-4da2-9792-176a6565f8e5",
   "metadata": {},
   "source": [
    "def train_model(train_x, train_y):\n",
    "    model = HistGradientBoostingRegressor(random_state=42)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a3d634a1-d3ab-466c-8cf8-b9d5479dfa10",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "72c907bf-ae7c-4a0d-ab24-aabdb6e539e0",
   "metadata": {},
   "source": [
    "def get_errors(model, x, y):\n",
    "    preds = model.predict(x)\n",
    "    training_errors = (y - preds)**2\n",
    "    return training_errors"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4392f377-a6b3-4e8d-9c13-9c20e20d7d55",
   "metadata": {},
   "source": [
    "def get_rms(arr):\n",
    "    means = sts.mean(arr)\n",
    "    rms = math.sqrt(means)\n",
    "    return rms"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db5bcfc3-8c71-4326-b642-7bcd6157a45e",
   "metadata": {},
   "source": [
    "def get_rms_error(model, x, y):\n",
    "    errors = get_errors(model, x, y)\n",
    "    return get_rms(errors)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1ed445-9ef4-45ba-82c1-06f7628b5330",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cd9cccd4-c960-45f2-bb45-e56b84385238",
   "metadata": {},
   "source": [
    "def bin_xs(train_x, train_errors):\n",
    "    optimal_binner = optbinning.ContinuousOptimalBinning(max_n_bins=5)\n",
    "    train_x_binned = pd.DataFrame(np.array(\n",
    "        [\n",
    "            optimal_binner.fit_transform(train_x[col], train_errors, metric=\"bins\") for col in train_x.columns\n",
    "        ]\n",
    "    ).T, columns=train_x.columns)\n",
    "    return train_x_binned"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "08c46518-dffb-48c5-9555-755b5e5ea858",
   "metadata": {},
   "source": [
    "### Sliceliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa1bfca7-f913-4575-9ca2-634ca2630042",
   "metadata": {},
   "source": [
    "def get_slices(train_x_binned, train_errors, alpha = 0.9, k=1, max_l = 3, min_sup = 0, verbose = False):\n",
    "    sf = Slicefinder(alpha = alpha, k = k, max_l = max_l, min_sup = min_sup, verbose = verbose)\n",
    "    sf.fit(train_x_binned, train_errors)\n",
    "    df = pd.DataFrame(sf.top_slices_, columns=sf.feature_names_in_, index=sf.get_feature_names_out())\n",
    "    return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "009f1f5f-4583-4ec8-980c-6e552e1242dd",
   "metadata": {},
   "source": [
    "# Reformat slices returned from sliceliner as dataframe into a matrix of strings\n",
    "def reformat_slices(slice_df):\n",
    "    slice_df.fillna('(-inf, inf)', inplace=True)\n",
    "    slice_list = slice_df.values.tolist()\n",
    "    slice_parsed = dt.parse_slices(slice_list)\n",
    "    return slice_parsed"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2303fd8-af99-44c6-a5c5-d4db490663b2",
   "metadata": {},
   "source": [
    "# Get the number of times each slice already exists in xs\n",
    "def get_slice_cnts(xs, slices):\n",
    "    cnts = []\n",
    "    for slice_ in slices:\n",
    "        cnt = 0\n",
    "        for x in xs.values.tolist():\n",
    "            if dt.belongs_to_slice(slice_, x):\n",
    "                cnt += 1 \n",
    "        cnts.append(cnt)\n",
    "    return cnts"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "32dc02db-3764-4495-b267-5b53d8de20bf",
   "metadata": {},
   "source": [
    "### Putting the Pipeline Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "efd15bc5-736f-4900-acaf-b07db9188117",
   "metadata": {},
   "source": [
    "# Train a model, report errors, and return model & binned train set\n",
    "def pipeline_train(train_x, train_y, test_x, test_y):\n",
    "    # Train model\n",
    "    model = train_model(train_x, train_y)\n",
    "    # Error analysis\n",
    "    train_errors = get_errors(model, train_x, train_y)\n",
    "    print(\"Train RMS error:\", get_rms(train_errors))\n",
    "    print(\"Test RMS error:\", get_rms(get_errors(model, test_x, test_y)))\n",
    "    # Binning\n",
    "    train_x_binned = bin_xs(train_x, train_errors)\n",
    "    return model, train_x_binned, train_errors"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "602a62c0-0bb3-4130-a839-77e88f7ffe71",
   "metadata": {},
   "source": [
    "def pipeline_sliceline(train_x, train_x_binned, train_errors, alpha = 0.9, max_l = 3, min_sup = 0, k = 1):\n",
    "    # Sliceliner\n",
    "    slices_df = get_slices(train_x_binned, train_errors, alpha = 0.9, max_l = 3, min_sup = 0, verbose = False, k=k)\n",
    "    slices = reformat_slices(slices_df)\n",
    "    existing_cnts = get_slice_cnts(train_x, slices)\n",
    "    print(\"Slices:\")\n",
    "    print(slices_df)\n",
    "    print(\"Existing counts:\", existing_cnts)\n",
    "    return slices"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "412d2d4b-ca27-4950-8d80-61dfdb546ff8",
   "metadata": {},
   "source": [
    "# Obtain additional data\n",
    "def pipeline_dt(sources, costs, slices, query_counts):\n",
    "    dt = DT(sources, costs, slices, None, batch=100)\n",
    "    additional_data = dt.run(query_counts)\n",
    "    return additional_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ece0af3-f67a-4769-8a13-a5b56ca0e8e7",
   "metadata": {},
   "source": [
    "# Combine existing dataset with additional data\n",
    "# Additional data is shuffled in\n",
    "def pipeline_augment(train_x, train_y, additional_data, features):\n",
    "    add_df = pd.DataFrame(additional_data, columns=features)\n",
    "    add_x, add_y = split_xy(add_df)\n",
    "    aug_x = pd.concat([train_x, add_x], ignore_index=True)\n",
    "    aug_x = aug_x.sample(frac=1, random_state=12345)\n",
    "    aug_y = pd.concat([train_y, add_y], ignore_index=True)\n",
    "    aug_y = aug_y.sample(frac=1, random_state=12345)\n",
    "    return aug_x, aug_y"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b6dee5eb-348a-4f7c-81e8-e72573c3d388",
   "metadata": {},
   "source": [
    "## Housing Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "188a28ed-a5a6-4e5c-8e4c-1a3bc4e72a89",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "train_x, train_y, train = parse_file('data/housing0.csv')\n",
    "test_x, test_y, test = parse_file('data/housing1.csv')\n",
    "train_x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d1a68e7-da88-422b-a1bf-a22b98433604",
   "metadata": {},
   "source": [
    "model, train_x_binned, train_errors = pipeline_train(train_x, train_y, test_x, test_y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "56e5a425-416f-4239-b262-c7728f692d04",
   "metadata": {},
   "source": [
    "slices = pipeline_sliceline(train_x, train_x_binned, train_errors, alpha = 0.5, max_l = 3, min_sup = 0, k = 3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "86876618-cd46-4096-b801-b18b5a880704",
   "metadata": {},
   "source": [
    "sources = [\n",
    "    'data/housing2.csv',\n",
    "    'data/housing3.csv',\n",
    "    'data/housing4.csv'\n",
    "]\n",
    "costs = [1.0, 1.0, 1.0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b11cac8c-64f7-4e4b-8de6-947219649f29",
   "metadata": {},
   "source": [
    "# We will consider only one slice\n",
    "# median income in [2.60, inf)\n",
    "query_counts = [ 300, 200 ]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "131dbc40-d03a-48a1-823d-363d35e2bcae",
   "metadata": {},
   "source": [
    "additional_data = pipeline_dt(sources, costs, slices, query_counts)\n",
    "additional_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d224e7ea-6667-4322-97f8-fcd8a4e94150",
   "metadata": {},
   "source": [
    "aug_x, aug_y = pipeline_augment(train_x, train_y, additional_data, train.columns)\n",
    "aug_x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "efe7244c-a9b2-453a-b656-bc56964b78a0",
   "metadata": {},
   "source": [
    "model, aug_x_binned, train_errors = pipeline_train(aug_x, aug_y, test_x, test_y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "801370e9-f5d3-4136-9112-9edbb13e7caa",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "slices = pipeline_sliceline(aug_x, aug_x_binned, train_errors, alpha = 0.5, max_l = 3, min_sup = 0, k = 3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0aaeb05c-7c77-4a83-b236-ab0b01a7262c",
   "metadata": {},
   "source": [
    "additional_data = pipeline_dt(sources, costs, slices, [290])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "152c4fe3-fadb-460e-8b6b-357018be2c42",
   "metadata": {},
   "source": [
    "additional_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b0f1fe71-ce7f-47ab-b73e-840ad20758b7",
   "metadata": {},
   "source": [
    "aug_x, aug_y = pipeline_augment(aug_x, aug_y, additional_data, train.columns)\n",
    "aug_x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6a35ce36-5de7-4747-b254-7d737c6eaf0a",
   "metadata": {},
   "source": [
    "model, aug_x_binned, train_errors = pipeline_train(aug_x, aug_y, test_x, test_y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1bd7ce08-c57c-4e76-b141-eeb68f70a5f5",
   "metadata": {},
   "source": [
    "slices = pipeline_sliceline(aug_x, aug_x_binned, train_errors, alpha = 0.5, max_l = 3, min_sup = 0, k = 3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "52471345-308e-4665-951e-de10db1c7b4a",
   "metadata": {},
   "source": [
    "additional_data = pipeline_dt(sources, costs, slices, [320, 180, 270])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3140d515-2429-45ff-8d42-be89c14335cf",
   "metadata": {},
   "source": [
    "additional_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8a3052d-1b06-453e-98fe-baa67a80f9a3",
   "metadata": {},
   "source": [
    "model, aug_x_binned, train_errors = pipeline_train(aug_x, aug_y, test_x, test_y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf5ee4-708f-45c5-8caa-80e29a8a6bb6",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
